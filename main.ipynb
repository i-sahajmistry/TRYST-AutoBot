{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all the required modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from jetbot import Robot\n",
    "from tensorflow import convert_to_tensor, expand_dims, uint8\n",
    "from torchsummary import summary\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the class instance as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "robot = Robot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I DONT KNOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def get_model(path, out):\n",
    "    model = Alexnet.alexnet(pretrained=True)\n",
    "\n",
    "    model.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, out)\n",
    "        )\n",
    "\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define some functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def region_of_interest(img, vertices):\n",
    "    mask = np.zeros_like(img)\n",
    "    #channel_count = img.shape[2]\n",
    "    match_mask_color = 255\n",
    "    cv2.fillPoly(mask, vertices, match_mask_color)\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image\n",
    "\n",
    "\n",
    "def drow_the_lines(img, lines):\n",
    "    img = np.copy(img)\n",
    "    blank_image = np.zeros((img.shape[0], img.shape[1], 3), dtype=np.uint8)\n",
    "\n",
    "    try:\n",
    "        for line in lines:\n",
    "            for x1, y1, x2, y2 in line:\n",
    "                cv2.line(blank_image, (x1,y1), (x2,y2), (0, 255, 0), thickness=10)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    img = cv2.addWeighted(img, 0.8, blank_image, 1, 0.0)\n",
    "    return img\n",
    "\n",
    "\n",
    "def process(image):\n",
    "    print(image.shape)\n",
    "    height = image.shape[0]\n",
    "    width = image.shape[1]\n",
    "    region_of_interest_vertices = [\n",
    "        (0, height-10),\n",
    "        (0, height/2),\n",
    "        (height-10, height/2),\n",
    "        (height-10, height-10)\n",
    "    ]\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    canny_image = cv2.Canny(gray_image, 100, 120)\n",
    "    cropped_image = region_of_interest(canny_image,\n",
    "                    np.array([region_of_interest_vertices], np.int32),)\n",
    "    lines = cv2.HoughLinesP(cropped_image,\n",
    "                            rho=2,\n",
    "                            theta=np.pi/180,\n",
    "                            threshold=70,\n",
    "                            lines=np.array([]),\n",
    "                            minLineLength=30,\n",
    "                            maxLineGap=100)\n",
    "    image_with_lines = drow_the_lines(image, lines)\n",
    "    return image_with_lines\n",
    "\n",
    "\n",
    "\n",
    "def getProbability(image, detectors):\n",
    "    prob = []\n",
    "    \n",
    "    output = F.softmax(detectors[0](image))\n",
    "    if max(output) > 0.7:\n",
    "\n",
    "        p = np.argmax(output.detach().numpy())\n",
    "        if(p == 0):\n",
    "            prob.append('person')\n",
    "        elif(p == 1):\n",
    "            prob.append('animal')\n",
    "        else:\n",
    "            prob.append('roadCones')\n",
    "    else:\n",
    "        prob.append('Nothing')\n",
    "\n",
    "    output = F.softmax(detectors[1](image))\n",
    "    if max(output) > 0.7:\n",
    "\n",
    "        p = np.argmax(output.detach().numpy())\n",
    "        if(p == 0):\n",
    "            prob.append('Stop')\n",
    "        elif(p == 1):\n",
    "            prob.append('Trafic Light - Blue')\n",
    "        elif(p == 1):\n",
    "            prob.append('Trafic Light - Red')\n",
    "        else:\n",
    "            prob.append('Trafic Light - Green')\n",
    "    else:\n",
    "        prob.append('Nothing')\n",
    "\n",
    "    output = detectors[2](image)\n",
    "    p = F.softmax(output)\n",
    "    prob.append(p[0])\n",
    "    return prob\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "width = 224\n",
    "height = 224\n",
    "\n",
    "path = [\"./72.4(Alexnet).pth\", \"./stop_and_traffic(65.7).pth\",\"./zebra.pth\"]\n",
    "detectors = []\n",
    "\n",
    "detectors.append(get_model(path[0], 3))\n",
    "detectors.append(get_model(path[1], 4))\n",
    "detectors.append(get_model(path[2], 2))\n",
    "\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    img = cv2.resize(frame, (width , height ))\n",
    "    rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    rgb_tensor = torch.Tensor(rgb)\n",
    "    rgb_tensor = torch.permute(rgb_tensor,(2,0,1))\n",
    "    # rgb_tensor = convert_to_tensor(rgb, dtype=uint8)                      # commented now hgfs\n",
    "    # rgb_tensor = expand_dims(rgb_tensor , 0)\n",
    "\n",
    "    # print(\"=>\", rgb_tensor)\n",
    "    # print(\"=>\", detectors)\n",
    "    pred = getProbability(rgb_tensor, detectors)\n",
    "\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    # frame = cv2.putText(frame, f'A {pred[0]:.2f}', (20, 20), font, 1, (25, 25, 25), 2, cv2.LINE_AA)\n",
    "    # frame = cv2.putText(frame, f'B {pred[1]:.2f}', (20, 50), font, 1, (25, 25, 25), 2, cv2.LINE_AA)\n",
    "    # frame = cv2.putText(frame, f'C: {pred[2]:.2f}', (20, 80), font, 1, (25, 25, 25), 2, cv2.LINE_AA)\n",
    "    frame = cv2.putText(frame, f'D: {pred[0]}', (20, 50), font, 1, (25, 25, 25), 2, cv2.LINE_AA)\n",
    "    frame = cv2.putText(frame, f'D: {pred[1]:.2f}', (20, 110), font, 1, (25, 25, 25), 2, cv2.LINE_AA)\n",
    "    \n",
    "    frame = process(frame)\n",
    "    cv2.imshow('frame', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
